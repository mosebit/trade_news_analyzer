"""
–°–∫—Ä–∏–ø—Ç –º–∏–≥—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ SQLite + sqlite-vec –≤ ChromaDB

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python migrate_to_chroma.py path/to/news_data.db
    python migrate_to_chroma.py path/to/news_data.db --chroma-path ./new_chroma_db
"""

import sqlite3
import chromadb
import json
import sys
import argparse
from typing import Dict, List
from tqdm import tqdm


def load_news_from_sqlite(db_path: str) -> List[Dict]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ SQLite –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö.
    
    Args:
        db_path: –ø—É—Ç—å –∫ SQLite –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        
    Returns:
        —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –¥–∞–Ω–Ω—ã–º–∏ –Ω–æ–≤–æ—Å—Ç–µ–π
    """
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –Ω–æ–≤–æ—Å—Ç–∏ —Å —Ç–∏–∫–µ—Ä–∞–º–∏
    query = """
        SELECT 
            n.id,
            n.url,
            n.title,
            n.original_text,
            n.clean_description,
            n.sentiment,
            n.impact_level,
            n.published_date,
            n.published_timestamp,
            GROUP_CONCAT(nt.ticker) as tickers
        FROM news n
        LEFT JOIN news_tickers nt ON n.id = nt.news_id
        GROUP BY n.id
        ORDER BY n.id
    """
    
    cursor.execute(query)
    rows = cursor.fetchall()
    
    news_list = []
    for row in rows:
        news_list.append({
            'id': row[0],
            'url': row[1],
            'title': row[2],
            'original_text': row[3] or '',
            'clean_description': row[4] or '',
            'sentiment': row[5] or 'neutral',
            'impact_level': row[6] or 'none',
            'published_date': row[7],
            'published_timestamp': row[8],
            'tickers': row[9].split(',') if row[9] else []
        })
    
    conn.close()
    return news_list


def migrate_to_chroma(sqlite_path: str, chroma_path: str = "./chroma_db"):
    """
    –ú–∏–≥—Ä–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ SQLite –≤ ChromaDB.
    
    Args:
        sqlite_path: –ø—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–π SQLite –±–∞–∑–µ
        chroma_path: –ø—É—Ç—å –¥–ª—è –Ω–æ–≤–æ–π ChromaDB –±–∞–∑—ã
    """
    print(f"üîÑ –ù–∞—á–∞–ª–æ –º–∏–≥—Ä–∞—Ü–∏–∏ –∏–∑ {sqlite_path} –≤ {chroma_path}")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ SQLite
    print("\nüìñ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ SQLite...")
    news_list = load_news_from_sqlite(sqlite_path)
    print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(news_list)} –Ω–æ–≤–æ—Å—Ç–µ–π")
    
    if len(news_list) == 0:
        print("‚ö† –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø—É—Å—Ç–∞, –Ω–µ—á–µ–≥–æ –º–∏–≥—Ä–∏—Ä–æ–≤–∞—Ç—å")
        return
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ChromaDB
    print(f"\nüì¶ –°–æ–∑–¥–∞–Ω–∏–µ ChromaDB –≤ {chroma_path}...")
    client = chromadb.PersistentClient(path=chroma_path)
    
    # –£–¥–∞–ª—è–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç (–¥–ª—è —á–∏—Å—Ç–æ–π –º–∏–≥—Ä–∞—Ü–∏–∏)
    try:
        client.delete_collection("news")
        print("‚úì –°—Ç–∞—Ä–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è —É–¥–∞–ª–µ–Ω–∞")
    except:
        pass
    
    # collection = client.create_collection("news")
    collection = client.get_or_create_collection("news_cosine", metadata={"hnsw:space": "cosine"})

    print("‚úì –ù–æ–≤–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∞")
    
    # –ú–∏–≥—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
    print(f"\nüöÄ –ú–∏–≥—Ä–∞—Ü–∏—è {len(news_list)} –Ω–æ–≤–æ—Å—Ç–µ–π...")
    
    # ChromaDB –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –±–∞—Ç—á–∏–Ω–≥ - –º–∏–≥—Ä–∏—Ä—É–µ–º –ø–æ 100 –∑–∞–ø–∏—Å–µ–π
    batch_size = 100
    migrated = 0
    errors = 0
    
    for i in tqdm(range(0, len(news_list), batch_size), desc="–ú–∏–≥—Ä–∞—Ü–∏—è"):
        batch = news_list[i:i+batch_size]
        
        ids = []
        documents = []
        metadatas = []
        
        for news in batch:
            try:
                # ID - –∏—Å–ø–æ–ª—å–∑—É–µ–º URL (—É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä)
                ids.append(news['url'])
                
                # Document - –æ—á–∏—â–µ–Ω–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
                documents.append(news['clean_description'])
                
                # Metadata - –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è
                original_text = news['original_text'][:3500] if news['original_text'] else ''
                
                # –°–æ–∑–¥–∞–µ–º enriched_data –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                enriched_data = {
                    'clean_description': news['clean_description'],
                    'sentiment': news['sentiment'],
                    'tickers_of_interest': news['tickers'],
                    'level_of_potential_impact_on_price': news['impact_level']
                }
                
                # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                metadata = {
                    'title': news['title'] or '',
                    'original_text': original_text,
                    'tickers': ','.join(news['tickers']),
                    'sentiment': news['sentiment'],
                    'impact': news['impact_level'],
                    'published_date': news['published_date'] or '',
                    'timestamp': news['published_timestamp'] or 0,
                    'enriched_json': json.dumps(enriched_data, ensure_ascii=False),
                    'sqlite_id': news['id']
                }
                
                # –ù–û–í–´–ô –ü–û–î–•–û–î: –¥–æ–±–∞–≤–ª—è–µ–º TICKER_impact —Ç–æ–ª—å–∫–æ –¥–ª—è —É–ø–æ–º—è–Ω—É—Ç—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤
                for ticker in news['tickers']:
                    if ticker.strip():  # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ —Ç–∏–∫–µ—Ä –Ω–µ –ø—É—Å—Ç–æ–π
                        metadata[f'{ticker.strip()}_impact'] = news['impact_level']
                
                metadatas.append(metadata)
                migrated += 1
                
            except Exception as e:
                print(f"\n‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –Ω–æ–≤–æ—Å—Ç–∏ {news.get('url', 'unknown')}: {e}")
                errors += 1
        
        # –î–æ–±–∞–≤–ª—è–µ–º –±–∞—Ç—á –≤ ChromaDB
        try:
            collection.add(
                ids=ids,
                documents=documents,
                metadatas=metadatas
            )
        except Exception as e:
            print(f"\n‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –±–∞—Ç—á–∞: {e}")
            errors += len(batch)
    
    # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\n" + "="*50)
    print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ú–ò–ì–†–ê–¶–ò–ò:")
    print(f"  ‚úì –£—Å–ø–µ—à–Ω–æ –º–∏–≥—Ä–∏—Ä–æ–≤–∞–Ω–æ: {migrated} –Ω–æ–≤–æ—Å—Ç–µ–π")
    if errors > 0:
        print(f"  ‚úó –û—à–∏–±–æ–∫: {errors}")
    print(f"  üìç ChromaDB –±–∞–∑–∞: {chroma_path}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞
    final_count = collection.count()
    print(f"  üîç –ó–∞–ø–∏—Å–µ–π –≤ ChromaDB: {final_count}")
    
    if final_count == migrated:
        print("\n‚úÖ –ú–∏–≥—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
    else:
        print(f"\n‚ö† –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –æ–∂–∏–¥–∞–ª–æ—Å—å {migrated}, –Ω–∞–π–¥–µ–Ω–æ {final_count}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö
    print("\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö...")
    sample = collection.get(limit=1, include=['metadatas'])
    if sample['ids']:
        print("–ü—Ä–∏–º–µ—Ä –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–≤–æ–π –∑–∞–ø–∏—Å–∏:")
        metadata_keys = list(sample['metadatas'][0].keys())
        print(f"  –ü–æ–ª—è: {', '.join(metadata_keys)}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º TICKER_impact –ø–æ–ª—è
        ticker_fields = [k for k in metadata_keys if k.endswith('_impact')]
        if ticker_fields:
            print(f"  TICKER_impact –ø–æ–ª—è: {', '.join(ticker_fields)}")
    
    print("="*50)
    
    # –ü—Ä–∏–º–µ—Ä—ã –∑–∞–ø—Ä–æ—Å–æ–≤
    print("\nüí° –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –Ω–æ–≤–æ–π –±–∞–∑—ã:")
    print(f"""
from news_database_chroma import NewsDatabase

db = NewsDatabase(path="{chroma_path}")

# –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ —Ç–∏–∫–µ—Ä—É
sber_news = db.get_news_by_ticker("SBER", limit=10)

# –ü–æ–ª—É—á–∏—Ç—å —Ç–æ–ª—å–∫–æ –≤–∞–∂–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
sber_important = db.get_news_by_ticker("SBER", limit=10, min_impact='high')

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
stats = db.get_stats()
print(stats)
    """)


def main():
    parser = argparse.ArgumentParser(
        description='–ú–∏–≥—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ SQLite + sqlite-vec –≤ ChromaDB',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  python migrate_to_chroma.py news_data.db
  python migrate_to_chroma.py news_data.db --chroma-path ./my_chroma_db
  python migrate_to_chroma.py /path/to/news_data.db --chroma-path /path/to/chroma
        """
    )
    
    parser.add_argument(
        'sqlite_db',
        help='–ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–π SQLite –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö'
    )
    
    parser.add_argument(
        '--chroma-path',
        default='./chroma_db',
        help='–ü—É—Ç—å –¥–ª—è –Ω–æ–≤–æ–π ChromaDB –±–∞–∑—ã (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: ./chroma_db)'
    )
    
    args = parser.parse_args()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –∏—Å—Ö–æ–¥–Ω–æ–π –ë–î
    import os
    if not os.path.exists(args.sqlite_db):
        print(f"‚ùå –û—à–∏–±–∫–∞: —Ñ–∞–π–ª {args.sqlite_db} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        sys.exit(1)
    
    # –ó–∞–ø—É—Å–∫ –º–∏–≥—Ä–∞—Ü–∏–∏
    try:
        migrate_to_chroma(args.sqlite_db, args.chroma_path)
    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –º–∏–≥—Ä–∞—Ü–∏–∏: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()